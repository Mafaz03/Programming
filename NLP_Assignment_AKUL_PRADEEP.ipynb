{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mafaz03/Programming/blob/main/NLP_Assignment_AKUL_PRADEEP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Mohamed Faiz\n",
        "#210171601030\n",
        "\n"
      ],
      "metadata": {
        "id": "JSYCJsLi-crq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CAT-1 NLP ASSIGNMENT\n"
      ],
      "metadata": {
        "id": "zrmxkkcxb6Zw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exercise 1**: *Basic Text Analytics*\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1t-PY2CScHkp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initiating a variable\n",
        "Sentence = \"Theres always room for improvement\"\n"
      ],
      "metadata": {
        "id": "-8FsyCW3ckWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"room\" in Sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "142xPxRic1OZ",
        "outputId": "dc351628-2da9-49db-9140-97766802cc5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xUT5Q4-Jc69a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#To find out the index value of the word 'fox'\n",
        "Sentence.index(\"for\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0tEXpA9c7W1",
        "outputId": "a22d3880-b75f-4b82-fa17-2e801f7b4aef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#to find out the rank of the word 'lazy'\n",
        "Sentence.split().index(\"always\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXISB2V7dCfC",
        "outputId": "75683d65-a600-43f0-bc6a-a886e835c270"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#printing the third word of the given text\n",
        "Sentence.split()[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4Mea2cPJdCyJ",
        "outputId": "ade62b10-4395-4b30-c4f8-5c25775c353e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'room'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#To print the third word of the given sentence in reverse order\n",
        "Sentence.split()[2][::-1]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3vm2GQB8dDBt",
        "outputId": "9a4bbaea-47a2-432f-d05f-6a9fd5b55ef8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'moor'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#concatenate the first and last words of the given sentence\n",
        "words = Sentence.split()\n",
        "first_word = words[0]\n",
        "last_word = words[len(words)-1]\n",
        "concat_word = first_word + last_word\n",
        "print(concat_word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qCwWJpHdDQL",
        "outputId": "da45dab3-32c9-4fd1-dcb3-ec7c10945758"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Theresimprovement\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#printing words at even positions\n",
        "[words[i] for i in range(len(words)) if i%2 == 0] # List Comprehension"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jzXSyoceXSf",
        "outputId": "21320267-986d-459d-f56d-fa92b1d3f8c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Theres', 'room', 'improvement']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print the last three letters of the text\n",
        "Sentence[-3:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0NjObBHveXZJ",
        "outputId": "bfae8226-f7ca-4050-ad14-43fca5246e75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ent'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to print the text in reverse order\n",
        "Sentence[::-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vPmt29w7eXcI",
        "outputId": "d30db4ae-d68e-41f7-e7f4-c82731a5fb00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'tnemevorpmi rof moor syawla serehT'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to print each word of the given text in reverse order, maintaining their sequence\n",
        "print(' '.join([word[::-1] for word in words]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKmZiir6eXrw",
        "outputId": "09f256ac-a12d-49fd-9ad8-d8eb6e0de40a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "serehT syawla moor rof tnemevorpmi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exercise 2** - *Tokenization of a Simple Sentence*"
      ],
      "metadata": {
        "id": "qZSRU--9cc0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing Necessary Library\n",
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aff6d24Qf5Aj",
        "outputId": "e21d6f13-bcd2-408a-b864-65e95eb512cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The word_tokenize() method is used to split the sentence into words/tokens\n",
        "\n",
        "Words = word_tokenize(\"Ignorance is the cause of fear.\")"
      ],
      "metadata": {
        "id": "YjyMxPzDf5R3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3_Bv1k1f5bw",
        "outputId": "faad29fb-6550-4b79-dc91-f149664f141f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Ignorance', 'is', 'the', 'cause', 'of', 'fear', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Words_sample1 =  word_tokenize(\"Stress is the result of avoiding your work you should be doing\")"
      ],
      "metadata": {
        "id": "rF4NUErLf5ew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Words_sample1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BR7XsRNkf5hg",
        "outputId": "9552c0dc-5ea9-4441-bedb-08bedb7220e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Stress',\n",
              " 'is',\n",
              " 'the',\n",
              " 'result',\n",
              " 'of',\n",
              " 'avoiding',\n",
              " 'your',\n",
              " 'work',\n",
              " 'you',\n",
              " 'should',\n",
              " 'be',\n",
              " 'doing']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exercise 3** -*PoS Tagging*"
      ],
      "metadata": {
        "id": "6Xr5ElgXiAvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Importing the necessary libraries\n",
        "import nltk\n",
        "from nltk import word_tokenise\"\"\"\n",
        "from nltk import pos_tag\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "id": "davUiHVviL23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e29d3a7b-a5b5-4b47-a7fc-4ceeb0ff3884"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In order to find the PoS for each word, we make use of the pos_tag() method\n",
        "nltk.pos_tag(Words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNCL2eirio4v",
        "outputId": "c0bb5480-d267-41ed-f634-ad2bffd8d706"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Ignorance', 'NN'),\n",
              " ('is', 'VBZ'),\n",
              " ('the', 'DT'),\n",
              " ('cause', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('fear', 'NN'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.pos_tag(Words_sample1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FsfG0R6kMaS",
        "outputId": "cc928a24-5e8a-4dce-8a1b-86d796741454"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Stress', 'NN'),\n",
              " ('is', 'VBZ'),\n",
              " ('the', 'DT'),\n",
              " ('result', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('avoiding', 'VBG'),\n",
              " ('your', 'PRP$'),\n",
              " ('work', 'NN'),\n",
              " ('you', 'PRP'),\n",
              " ('should', 'MD'),\n",
              " ('be', 'VB'),\n",
              " ('doing', 'VBG')]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exercise 4** - *Stop Word Removal*"
      ],
      "metadata": {
        "id": "AXgWxBUpk08-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "Yv2pwdF9k-9C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4faef7f1-023c-492d-bedd-5ee8265269b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To check the list of stopwords provided for the English language\n",
        "StopWords = stopwords.words('english')"
      ],
      "metadata": {
        "id": "IWM6XwsTlMb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range (len(StopWords)):\n",
        "  if i%15 == 0:\n",
        "    print(\"\\n-------------------------------------------------\")\n",
        "  print(StopWords[i],end =\",\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1APy_4klMef",
        "outputId": "26cd4456-9301-49a4-85de-4675d21e075b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-------------------------------------------------\n",
            "i,me,my,myself,we,our,ours,ourselves,you,you're,you've,you'll,you'd,your,yours,\n",
            "-------------------------------------------------\n",
            "yourself,yourselves,he,him,his,himself,she,she's,her,hers,herself,it,it's,its,itself,\n",
            "-------------------------------------------------\n",
            "they,them,their,theirs,themselves,what,which,who,whom,this,that,that'll,these,those,am,\n",
            "-------------------------------------------------\n",
            "is,are,was,were,be,been,being,have,has,had,having,do,does,did,doing,\n",
            "-------------------------------------------------\n",
            "a,an,the,and,but,if,or,because,as,until,while,of,at,by,for,\n",
            "-------------------------------------------------\n",
            "with,about,against,between,into,through,during,before,after,above,below,to,from,up,down,\n",
            "-------------------------------------------------\n",
            "in,out,on,off,over,under,again,further,then,once,here,there,when,where,why,\n",
            "-------------------------------------------------\n",
            "how,all,any,both,each,few,more,most,other,some,such,no,nor,not,only,\n",
            "-------------------------------------------------\n",
            "own,same,so,than,too,very,s,t,can,will,just,don,don't,should,should've,\n",
            "-------------------------------------------------\n",
            "now,d,ll,m,o,re,ve,y,ain,aren,aren't,couldn,couldn't,didn,didn't,\n",
            "-------------------------------------------------\n",
            "doesn,doesn't,hadn,hadn't,hasn,hasn't,haven,haven't,isn,isn't,ma,mightn,mightn't,mustn,mustn't,\n",
            "-------------------------------------------------\n",
            "needn,needn't,shan,shan't,shouldn,shouldn't,wasn,wasn't,weren,weren't,won,won't,wouldn,wouldn't,"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To remove the stopwords\n",
        "sentence_no_stops = ' '.join([word for word in Words if word not in StopWords])"
      ],
      "metadata": {
        "id": "b7EdHJUYlMg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_no_stops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "tOkM-Zp_n---",
        "outputId": "69c849b7-5d57-416c-b91a-f6332915cb68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Ignorance cause fear .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exercise 5** - *Text Nomalization*"
      ],
      "metadata": {
        "id": "koV7q2y5oMIW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"I visited US from UK vat the LA Airport on 21st june\""
      ],
      "metadata": {
        "id": "fkXW5QHjocXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalization\n",
        "normalized_sentence = sentence.replace(\"US\", \"United States\").replace(\"UK\", \"United Kingdom\").replace(\"LA\", \"Los Angeles\").replace(\"21\", \"19\")"
      ],
      "metadata": {
        "id": "83C71kzKocaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Acna-sfXocjl",
        "outputId": "fa95e42d-a77d-4432-a1e7-abda0c1d080c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I visited United States from United Kingdom on 22-10-2018'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exercise 6** - *Spell Correction of Words and Sentences*"
      ],
      "metadata": {
        "id": "XqTcSPa6o-u_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install autocorrect"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWvSl3emzd-L",
        "outputId": "1a0a05ea-e7fd-49cd-be1c-344faf800582"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting autocorrect\n",
            "  Downloading autocorrect-2.6.1.tar.gz (622 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m622.8/622.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: autocorrect\n",
            "  Building wheel for autocorrect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autocorrect: filename=autocorrect-2.6.1-py3-none-any.whl size=622364 sha256=af63acef2db1e28e53eb16f7f1101f4742795fdea1c22a19860afb3c06cf4f86\n",
            "  Stored in directory: /root/.cache/pip/wheels/b5/7b/6d/b76b29ce11ff8e2521c8c7dd0e5bfee4fb1789d76193124343\n",
            "Successfully built autocorrect\n",
            "Installing collected packages: autocorrect\n",
            "Successfully installed autocorrect-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "from autocorrect import spell"
      ],
      "metadata": {
        "id": "7sUhAIiDpSw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = word_tokenize(\"Acept te thngs to whih fate binds you, and love the peple with whom fate bings you togter, but do so with all yur heart.\")"
      ],
      "metadata": {
        "id": "vpwMfTwBqEfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uet7_wDLqPku",
        "outputId": "b312647e-c369-4478-a844-6be679e8723e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Acept', 'te', 'thngs', 'to', 'whih', 'fate', 'binds', 'you', ',', 'and', 'love', 'the', 'peple', 'with', 'whom', 'fate', 'bings', 'you', 'togter', ',', 'but', 'do', 'so', 'with', 'all', 'yur', 'heart', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_corrected = \" \".join([spell(words) for words in sentence ])"
      ],
      "metadata": {
        "id": "7HPyPz_DqVfI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "726ae615-dbd8-4ef6-d6c8-8f4ea5dabd0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_corrected"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "uocASSj9qVm_",
        "outputId": "9058c919-646a-40dc-81f7-c04740c065eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Accept te things to which fate binds you , and love the people with whom fate brings you together , but do so with all your heart .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exercise 7** - *Stemming*"
      ],
      "metadata": {
        "id": "L9BCmth-qq7R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = nltk.stem.PorterStemmer()"
      ],
      "metadata": {
        "id": "xOE2Q9C8tJHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer.stem(\"revenge\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YB9S_0ZEtOU3",
        "outputId": "679c887f-27f9-4d56-b69b-7ae7d0b91819"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'reveng'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer.stem(\"ridiculous\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RqVD0J_LtObo",
        "outputId": "c204758c-14df-48f1-bf99-c74b32079e20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ridicul'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer.stem(\"Confine\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3Qry0vQktgkl",
        "outputId": "f1cdfb03-fd6c-446e-a0b8-d3aea01cfd47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'confin'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exercise 8** - *Extracting base word using Lemmatization*"
      ],
      "metadata": {
        "id": "V18qjyWmt4Kw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Wy7Eoguswspv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary Libraries\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "id": "Cd4ZpmaRuMZv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfec3fde-2e0d-4f09-a35a-8361038131bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "UpC70-i6uWbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize('revenge')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Lfc20fiIuWih",
        "outputId": "1a1a6c44-e012-42df-deff-cb350f8d1e61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'revenge'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize('ridiculous')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "yJGtqN0-ujjO",
        "outputId": "f879f2a4-354a-4fc3-ac58-bb8b7b02ad9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ridiculous'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exercise 9** - *Named Entities*"
      ],
      "metadata": {
        "id": "SuoCdxSkuywe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "import nltk\n",
        "nltk.download('maxent_ne_chunker')\n",
        "import nltk\n",
        "\n",
        "# Set the NLTK data directory explicitly\n",
        "nltk.data.path.append(\"/usr/local/share/nltk_data\")\n",
        "\n",
        "# Download the \"words\" corpus\n",
        "nltk.download('words')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcMLZgnsxd84",
        "outputId": "a9f2462a-09a6-4ff2-b71e-0f0128ee3196"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"Consider at what price you sell your integrity, but please, for God’s sake, don’t sell it cheap.\""
      ],
      "metadata": {
        "id": "X_Qw-2hfu-Ue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import NLTK library and necessary modules\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "sentence = \"Your sentence here\"\n",
        "tokens = word_tokenize(sentence)\n",
        "pos_tags = nltk.pos_tag(tokens)\n",
        "ne_chunked = nltk.ne_chunk(pos_tags, binary=True)\n",
        "filtered_entities = [chunk for chunk in ne_chunked if isinstance(chunk, nltk.Tree) and len(chunk) == 1]\n",
        "print(filtered_entities)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuYOn5bQvSRS",
        "outputId": "5240079f-c422-4205-e6ee-7130a8d518f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exercise 10** - *Word Sense Diasmbiguation*"
      ],
      "metadata": {
        "id": "P6h10hMdvmu1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary Libraries\n",
        "from nltk.wsd import lesk"
      ],
      "metadata": {
        "id": "OrY1XtpavyA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence1 = \"He who thinks all the time, gets nothing done.\"\n",
        "sentence2 = \"Discipline over Regret.\""
      ],
      "metadata": {
        "id": "exZPsvtTwBMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(lesk(word_tokenize(sentence1), 'star'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tk3Vof5PwaD2",
        "outputId": "f664a740-9b42-429e-f51d-c3f1da2447c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset('star.v.02')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(lesk(word_tokenize(sentence2), 'star'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fyHEhdawogI",
        "outputId": "26eef1ed-5bdd-4e59-8827-20dfa2e4590e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset('star_topology.n.01')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exercise 11** - *Sentence boundary Detection*"
      ],
      "metadata": {
        "id": "j0z5_hk4wvC9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary Libraries\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "a5WhD_J-w56_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17b30dc3-8aef-4599-fd02-df1926a5e434"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent_tokenize(\"We are playing a game in a cafe. Do you wanna join?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86fyLt2QxGNF",
        "outputId": "77a968a7-f9d4-4265-d082-fe1ee568e5b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['We are playing a game in a cafe.', 'Do you wanna join?']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    }
  ]
}